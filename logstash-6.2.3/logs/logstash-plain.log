[2018-05-08T14:03:45,936][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T14:03:45,984][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T14:03:46,164][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T14:03:46,632][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T14:03:47,171][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T14:03:49,168][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T14:03:49,727][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x21589445 run>"}
[2018-05-08T14:03:49,795][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T14:04:01,868][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO 错误: The Network Adapter could not establish the connection"}
[2018-05-08T14:05:01,039][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO 错误: The Network Adapter could not establish the connection"}
[2018-05-08T14:05:29,280][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T14:05:34,285][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2018-05-08T14:05:34,399][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>29, "name"=>"[main]<jdbc", "current_call"=>"[...]/vendor/bundle/jruby/2.3.0/gems/rufus-scheduler-3.0.9/lib/rufus/scheduler.rb:170:in `join'"}, {"thread_id"=>25, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}, {"thread_id"=>26, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}, {"thread_id"=>27, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}, {"thread_id"=>28, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}]}}
[2018-05-08T14:05:34,408][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2018-05-08T14:05:39,392][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>29, "name"=>"[main]<jdbc", "current_call"=>"[...]/vendor/bundle/jruby/2.3.0/gems/rufus-scheduler-3.0.9/lib/rufus/scheduler.rb:170:in `join'"}, {"thread_id"=>25, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}, {"thread_id"=>26, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}, {"thread_id"=>27, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}, {"thread_id"=>28, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}]}}
[2018-05-08T14:05:43,405][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2018-05-08T14:05:43,968][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2018-05-08T14:05:44,391][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>29, "name"=>"[main]<jdbc", "current_call"=>"[...]/vendor/bundle/jruby/2.3.0/gems/rufus-scheduler-3.0.9/lib/rufus/scheduler.rb:170:in `join'"}, {"thread_id"=>25, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}, {"thread_id"=>26, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}, {"thread_id"=>27, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}, {"thread_id"=>28, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}]}}
[2018-05-08T14:06:44,210][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T14:06:44,226][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T14:06:44,396][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T14:06:44,857][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T14:06:45,467][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T14:06:47,926][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_10da69a3-fb91-45b9-8bf7-01b8566b2dea", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T14:06:48,099][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T14:06:48,439][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T14:06:48,448][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T14:06:48,654][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T14:06:48,760][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T14:06:48,765][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T14:06:48,796][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T14:06:48,813][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T14:06:49,644][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T14:06:50,129][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x327f4304 run>"}
[2018-05-08T14:06:50,206][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T14:07:00,907][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComMicrosoftSqlserverJdbc::SQLServerException: 用户 'vrvsync' 登录失败。 ClientConnectionId:c4f70eec-17b8-43df-b232-5006f2bf5056"}
[2018-05-08T14:08:00,187][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComMicrosoftSqlserverJdbc::SQLServerException: 用户 'vrvsync' 登录失败。 ClientConnectionId:5c61a1ed-3844-4f56-923e-98d02b1b556a"}
[2018-05-08T14:09:43,126][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T14:09:43,143][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T14:09:43,318][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T14:09:43,773][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T14:09:44,187][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T14:09:46,751][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_2156f7bd-0de0-44b6-900c-376c06b08186", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T14:09:46,933][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T14:09:47,311][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T14:09:47,323][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T14:09:47,496][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T14:09:47,591][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T14:09:47,595][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T14:09:47,609][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T14:09:47,626][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T14:09:47,665][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T14:09:48,097][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0xf52b1a2 sleep>"}
[2018-05-08T14:09:48,172][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T14:10:01,637][INFO ][logstash.inputs.jdbc     ] (0.352000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= 0;
[2018-05-08T14:10:01,700][WARN ][logstash.inputs.jdbc     ] Exception when executing JDBC query {:exception=>#<Sequel::DatabaseError: Java::ComMicrosoftSqlserverJdbc::SQLServerException: å¨å° nvarchar å¼ '2018-04-25 10:56:19' è½¬æ¢ææ°æ®ç±»å int æ¶å¤±è´¥ã>}
[2018-05-08T14:10:44,630][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T14:10:45,689][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0xf52b1a2 run>"}
[2018-05-08T14:11:51,950][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T14:11:51,971][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T14:11:52,149][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T14:11:52,604][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T14:11:52,999][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T14:11:55,611][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_418286c5-2612-46a5-9115-83c715bc4014", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T14:11:55,788][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T14:11:56,161][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T14:11:56,172][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T14:11:56,330][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T14:11:56,431][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T14:11:56,434][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T14:11:56,448][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T14:11:56,464][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T14:11:56,500][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T14:11:56,933][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x6ed74e0 run>"}
[2018-05-08T14:11:57,001][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T14:12:01,089][INFO ][logstash.inputs.jdbc     ] (0.039000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= NULL;
[2018-05-08T14:13:00,042][INFO ][logstash.inputs.jdbc     ] (0.002000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= NULL;
[2018-05-08T14:14:00,230][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= NULL;
[2018-05-08T14:14:01,529][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T14:14:02,593][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x6ed74e0 run>"}
[2018-05-08T14:15:07,208][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T14:15:07,224][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T14:15:07,418][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T14:15:07,901][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T14:15:08,346][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T14:15:10,844][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_636cc519-9824-4258-8a39-1b9dd2785acb", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T14:15:11,018][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T14:15:11,359][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T14:15:11,368][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T14:15:11,562][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T14:15:11,608][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T14:15:11,611][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T14:15:11,624][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T14:15:11,639][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T14:15:11,675][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T14:15:12,124][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x593d7255 sleep>"}
[2018-05-08T14:15:12,194][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T14:16:01,278][INFO ][logstash.inputs.jdbc     ] (0.042000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:16:01,344][WARN ][logstash.inputs.jdbc     ] tracking_column not found in dataset. {:tracking_column=>"dbo.FileLog2201804.operationTime"}
[2018-05-08T14:16:10,292][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T14:17:00,070][INFO ][logstash.inputs.jdbc     ] (0.004000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:17:00,075][WARN ][logstash.inputs.jdbc     ] tracking_column not found in dataset. {:tracking_column=>"dbo.FileLog2201804.operationTime"}
[2018-05-08T14:18:00,252][INFO ][logstash.inputs.jdbc     ] (0.004000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:18:00,256][WARN ][logstash.inputs.jdbc     ] tracking_column not found in dataset. {:tracking_column=>"dbo.FileLog2201804.operationTime"}
[2018-05-08T14:18:38,162][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T14:18:38,850][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x593d7255 run>"}
[2018-05-08T14:19:34,507][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T14:19:34,523][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T14:19:34,708][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T14:19:35,189][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T14:19:35,597][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T14:19:38,359][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_ad13af28-0208-4557-86de-5e8ab7c64f8f", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T14:19:38,533][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T14:19:38,878][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T14:19:38,887][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T14:19:39,069][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T14:19:39,119][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T14:19:39,122][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T14:19:39,136][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T14:19:39,153][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T14:19:39,192][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T14:19:39,664][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x6cf60496 run>"}
[2018-05-08T14:19:39,743][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T14:20:01,493][INFO ][logstash.inputs.jdbc     ] (0.043000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:20:01,562][WARN ][logstash.inputs.jdbc     ] tracking_column not found in dataset. {:tracking_column=>"operationTime"}
[2018-05-08T14:20:02,110][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T14:20:29,732][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T14:20:31,210][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x6cf60496 run>"}
[2018-05-08T14:21:15,480][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T14:21:15,497][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T14:21:15,689][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T14:21:16,111][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T14:21:16,499][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T14:21:19,163][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_21ee44ee-c881-440b-a0f0-42685bc0392c", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T14:21:19,335][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T14:21:19,719][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T14:21:19,727][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T14:21:19,901][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T14:21:19,956][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T14:21:19,959][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T14:21:19,974][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T14:21:19,993][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T14:21:20,032][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T14:21:20,542][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x34809dec run>"}
[2018-05-08T14:21:20,662][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T14:22:01,363][INFO ][logstash.inputs.jdbc     ] (0.037000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:22:01,923][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T14:23:00,143][INFO ][logstash.inputs.jdbc     ] (0.002000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:24:00,327][INFO ][logstash.inputs.jdbc     ] (0.003000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:25:00,256][INFO ][logstash.inputs.jdbc     ] (0.003000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:26:00,150][INFO ][logstash.inputs.jdbc     ] (0.004000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:26:30,042][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T14:26:31,298][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x34809dec run>"}
[2018-05-08T14:26:59,122][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T14:26:59,137][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T14:26:59,308][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T14:26:59,761][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T14:27:00,166][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T14:27:02,355][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_513e603c-008d-4e92-89c6-e71610dc8206", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T14:27:02,529][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T14:27:02,855][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T14:27:02,864][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T14:27:03,039][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T14:27:03,086][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T14:27:03,089][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T14:27:03,103][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T14:27:03,121][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T14:27:03,156][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T14:27:03,620][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0xcaf2a76 sleep>"}
[2018-05-08T14:27:03,693][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T14:28:01,208][INFO ][logstash.inputs.jdbc     ] (0.039000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:28:02,069][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T14:29:00,326][INFO ][logstash.inputs.jdbc     ] (0.003000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:30:00,210][INFO ][logstash.inputs.jdbc     ] (0.003000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:31:00,103][INFO ][logstash.inputs.jdbc     ] (0.003000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:32:00,302][INFO ][logstash.inputs.jdbc     ] (0.004000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:33:00,191][INFO ][logstash.inputs.jdbc     ] (0.003000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:33:51,237][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T14:33:52,511][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0xcaf2a76 run>"}
[2018-05-08T14:36:00,644][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T14:36:00,657][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T14:36:00,834][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T14:36:01,279][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T14:36:01,697][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T14:36:04,231][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_d60dfbe7-fff3-4faa-87f7-cfd60fe9d9f6", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T14:36:04,409][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T14:36:04,744][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T14:36:04,754][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T14:36:04,943][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T14:36:05,024][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T14:36:05,028][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T14:36:05,042][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T14:36:05,061][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T14:36:05,098][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T14:36:05,527][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x5ff6e885 run>"}
[2018-05-08T14:36:05,623][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T14:37:01,357][INFO ][logstash.inputs.jdbc     ] (0.040000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:37:02,085][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T14:38:00,137][INFO ][logstash.inputs.jdbc     ] (0.004000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:39:00,329][INFO ][logstash.inputs.jdbc     ] (0.004000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:40:00,215][INFO ][logstash.inputs.jdbc     ] (0.004000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:41:00,111][INFO ][logstash.inputs.jdbc     ] (0.003000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:42:00,303][INFO ][logstash.inputs.jdbc     ] (0.003000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:42:05,466][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T14:42:06,403][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x5ff6e885 run>"}
[2018-05-08T14:49:52,731][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T14:49:52,744][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T14:49:52,922][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T14:49:53,382][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T14:49:53,820][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T14:49:56,428][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_72e33e1a-4ee9-4379-aaae-2e72b5c310a3", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T14:49:58,635][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T14:49:59,004][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T14:49:59,012][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T14:49:59,157][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T14:49:59,223][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T14:49:59,230][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T14:49:59,250][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T14:49:59,265][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T14:49:59,304][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T14:49:59,785][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x3aedef81 sleep>"}
[2018-05-08T14:49:59,880][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T14:51:01,163][INFO ][logstash.inputs.jdbc     ] (0.041000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= NULL;
[2018-05-08T14:52:00,099][INFO ][logstash.inputs.jdbc     ] (0.002000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= NULL;
[2018-05-08T14:53:00,285][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= NULL;
[2018-05-08T14:53:18,434][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T14:53:19,469][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x3aedef81 run>"}
[2018-05-08T14:54:01,548][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T14:54:01,564][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T14:54:01,788][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T14:54:02,274][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T14:54:02,687][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T14:54:05,259][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_7f7dd5b9-52b9-49a3-8e09-e5cb6fb3ca8d", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T14:54:07,444][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T14:54:07,848][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T14:54:07,857][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T14:54:08,018][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T14:54:08,067][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T14:54:08,072][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T14:54:08,087][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T14:54:08,106][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T14:54:08,143][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T14:54:08,601][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x5ebf8cf1 run>"}
[2018-05-08T14:54:08,692][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T14:55:01,399][INFO ][logstash.inputs.jdbc     ] (0.040000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:55:02,692][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T14:56:00,281][INFO ][logstash.inputs.jdbc     ] (0.004000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:56:42,200][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T14:56:43,367][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x5ebf8cf1 run>"}
[2018-05-08T14:57:30,653][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T14:57:30,668][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T14:57:30,852][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T14:57:31,313][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T14:57:31,951][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T14:57:34,325][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_07978594-d1d5-4660-bdd6-bc153b13c9c5", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T14:57:34,504][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T14:57:34,840][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T14:57:34,848][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T14:57:35,039][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T14:57:35,098][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T14:57:35,103][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T14:57:35,116][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T14:57:35,131][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T14:57:35,168][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T14:57:35,613][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x105eba02 sleep>"}
[2018-05-08T14:57:35,701][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T14:58:01,415][INFO ][logstash.inputs.jdbc     ] (0.037000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:58:02,032][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T14:59:00,181][INFO ][logstash.inputs.jdbc     ] (0.004000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T14:59:04,168][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T14:59:05,224][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x105eba02 run>"}
[2018-05-08T15:00:01,268][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T15:00:01,282][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T15:00:01,463][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T15:00:01,972][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T15:00:02,415][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T15:00:04,797][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_a53b4052-54ce-4ac5-9696-307a531bf19a", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T15:00:05,033][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T15:00:05,377][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T15:00:05,387][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T15:00:05,572][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T15:00:05,622][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T15:00:05,691][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T15:00:05,730][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T15:00:05,749][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T15:00:05,790][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T15:00:06,245][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x5e8aec12 run>"}
[2018-05-08T15:00:06,317][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T15:01:01,480][INFO ][logstash.inputs.jdbc     ] (0.037000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:01:01,543][WARN ][logstash.inputs.jdbc     ] tracking_column not found in dataset. {:tracking_column=>"dbo.filelog2201804.operationtime"}
[2018-05-08T15:01:02,196][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T15:02:00,259][INFO ][logstash.inputs.jdbc     ] (0.003000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:02:00,266][WARN ][logstash.inputs.jdbc     ] tracking_column not found in dataset. {:tracking_column=>"dbo.filelog2201804.operationtime"}
[2018-05-08T15:02:04,910][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T15:02:05,877][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x5e8aec12 run>"}
[2018-05-08T15:02:46,621][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T15:02:46,638][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T15:02:46,828][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T15:02:47,268][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T15:02:47,661][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T15:02:50,132][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_487091c9-dce6-4248-9066-697abe7e229d", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T15:02:50,309][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T15:02:50,652][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T15:02:50,661][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T15:02:50,847][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T15:02:50,896][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T15:02:50,899][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T15:02:50,912][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T15:02:50,930][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T15:02:50,967][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T15:02:51,442][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x6ba0902e sleep>"}
[2018-05-08T15:02:51,523][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T15:03:01,541][INFO ][logstash.inputs.jdbc     ] (0.039000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:03:02,368][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T15:03:47,722][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T15:03:48,993][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x6ba0902e run>"}
[2018-05-08T15:04:26,922][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T15:04:26,939][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T15:04:27,109][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T15:04:27,557][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T15:04:27,966][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T15:04:30,364][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_8c782870-8393-4a60-a996-a309c7f89131", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T15:04:30,535][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T15:04:30,873][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T15:04:30,882][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T15:04:31,064][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T15:04:31,111][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T15:04:31,114][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T15:04:31,126][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T15:04:31,143][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T15:04:31,179][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T15:04:31,645][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x275f0b9b run>"}
[2018-05-08T15:04:31,751][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T15:05:01,321][INFO ][logstash.inputs.jdbc     ] (0.038000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:05:02,205][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T15:06:00,109][INFO ][logstash.inputs.jdbc     ] (0.003000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:07:00,295][INFO ][logstash.inputs.jdbc     ] (0.004000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:08:00,209][INFO ][logstash.inputs.jdbc     ] (0.004000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:09:00,106][INFO ][logstash.inputs.jdbc     ] (0.003000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:09:07,689][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T15:09:08,465][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x275f0b9b run>"}
[2018-05-08T15:10:55,162][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T15:10:55,176][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T15:10:55,356][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T15:10:55,827][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T15:10:56,387][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T15:10:58,719][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201805", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_4205ee10-776f-4552-b9df-7439b59a7129", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T15:10:58,902][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T15:10:59,258][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T15:10:59,265][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T15:10:59,446][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T15:10:59,494][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T15:10:59,497][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T15:10:59,513][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T15:10:59,530][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T15:10:59,564][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T15:10:59,995][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x29a87b8d sleep>"}
[2018-05-08T15:11:00,069][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T15:12:01,304][INFO ][logstash.inputs.jdbc     ] (0.049000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:12:03,287][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T15:13:01,720][INFO ][logstash.inputs.jdbc     ] (1.412000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operationTime >= '2018-05-08T15:12:00.999';
[2018-05-08T15:13:44,681][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T15:13:45,699][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x29a87b8d run>"}
[2018-05-08T15:14:40,487][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T15:14:40,503][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T15:14:40,683][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T15:14:41,150][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T15:14:41,519][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T15:14:44,569][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201805", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_c3b641db-b8c4-4a3f-bfe4-4e97d392ebaf", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T15:14:44,746][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T15:14:45,082][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T15:14:45,133][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T15:14:45,283][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T15:14:45,331][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T15:14:45,336][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T15:14:45,349][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T15:14:45,366][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T15:14:45,404][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T15:14:45,854][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x1773b5ac run>"}
[2018-05-08T15:14:45,960][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T15:15:01,355][INFO ][logstash.inputs.jdbc     ] (0.037000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:15:02,018][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T15:16:00,137][INFO ][logstash.inputs.jdbc     ] (0.004000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:16:41,588][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T15:16:42,487][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x1773b5ac run>"}
[2018-05-08T15:17:27,612][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T15:17:27,627][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T15:17:27,800][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T15:17:28,251][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T15:17:28,634][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T15:17:31,307][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201805", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_77bce1f3-ec09-4190-a8e0-598d7f8ac4a6", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T15:17:31,488][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T15:17:31,870][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T15:17:31,878][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T15:17:32,058][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T15:17:32,104][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T15:17:32,108][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T15:17:32,122][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T15:17:32,138][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T15:17:32,171][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T15:17:32,642][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x306eabfc run>"}
[2018-05-08T15:17:32,726][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T15:18:01,355][INFO ][logstash.inputs.jdbc     ] (0.081000s) SELECT  * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:18:02,792][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T15:20:33,621][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T15:28:41,840][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T15:28:41,891][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T15:28:42,140][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T15:28:42,617][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T15:28:43,123][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T15:28:45,599][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_c9359b8c-0ebc-40b2-a458-dfcf56929d9f", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T15:28:45,791][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T15:28:46,156][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T15:28:46,164][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T15:28:46,360][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T15:28:46,408][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T15:28:46,411][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T15:28:46,424][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T15:28:46,440][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T15:28:46,485][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T15:28:46,955][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x3cbb703e sleep>"}
[2018-05-08T15:28:47,044][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T15:29:01,259][INFO ][logstash.inputs.jdbc     ] (0.039000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:29:02,059][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T15:30:00,315][INFO ][logstash.inputs.jdbc     ] (0.004000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:30:40,672][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T15:30:41,554][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x3cbb703e run>"}
[2018-05-08T15:40:35,665][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T15:40:35,680][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T15:40:35,850][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T15:40:36,290][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T15:40:36,686][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T15:40:39,388][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_92ac36c2-7a85-45af-b594-e29fc629e87f", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T15:40:39,563][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T15:40:39,905][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T15:40:39,942][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T15:40:40,100][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T15:40:40,147][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T15:40:40,152][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T15:40:40,167][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T15:40:40,184][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T15:40:40,218][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T15:40:40,684][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x35780f4b run>"}
[2018-05-08T15:40:40,769][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T15:41:01,273][INFO ][logstash.inputs.jdbc     ] (0.038000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:41:01,939][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T15:42:00,811][INFO ][logstash.inputs.jdbc     ] (0.747000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '2018-05-08T15:41:00.997';
[2018-05-08T15:43:00,928][INFO ][logstash.inputs.jdbc     ] (0.683000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '2018-05-08T15:42:00.053';
[2018-05-08T15:44:00,873][INFO ][logstash.inputs.jdbc     ] (0.736000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '2018-05-08T15:43:00.239';
[2018-05-08T15:45:01,676][INFO ][logstash.inputs.jdbc     ] (1.343000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '2018-05-08T15:44:00.130';
[2018-05-08T15:45:25,703][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T15:45:26,003][INFO ][logstash.outputs.file    ] Closing file D:/vrv.txt
[2018-05-08T15:45:26,464][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x35780f4b run>"}
[2018-05-08T15:45:55,777][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T15:45:55,794][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T15:45:56,000][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T15:45:56,540][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T15:45:57,015][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T15:45:59,802][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f107319b-0275-4a8d-b06d-3cfb5ae0c535", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T15:46:00,020][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T15:46:00,413][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T15:46:00,422][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T15:46:00,576][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T15:46:00,626][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T15:46:00,630][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T15:46:00,645][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T15:46:00,664][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T15:46:00,704][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T15:46:01,104][ERROR][logstash.pipeline        ] Error registering plugin {:pipeline_id=>"main", :plugin=>"<LogStash::Inputs::Jdbc jdbc_driver_library=>\"c:/elk/logstash-6.2.3/lib/sqlserverdriver/mssql-jdbc-6.2.2.jre8.jar\", jdbc_driver_class=>\"com.microsoft.sqlserver.jdbc.SQLServerDriver\", jdbc_connection_string=>\"jdbc:sqlserver://10.6.201.6:1433;databaseName=CobraDGServer;\", jdbc_user=>\"logsync2\", jdbc_password=><password>, schedule=>\"* * * * *\", jdbc_default_timezone=>\"Asia/Shanghai\", statement=>\"SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= :sql_last_value;\", last_run_metadata_path=>\"result/test.logstash_jdbc_last_run\", use_column_value=>true, id=>\"40c0e96eda7bb1ee02e9d3c843c7ae858f388b30e7ffaf0ad38f0ebd72933cb2\", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>\"plain_80cef8c9-e183-4cc8-9566-e3853b6442f4\", enable_metric=>true, charset=>\"UTF-8\">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>\"info\", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, tracking_column_type=>\"numeric\", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>", :error=>"Must set :tracking_column if :use_column_value is true.", :thread=>"#<Thread:0x3ecb9046 run>"}
[2018-05-08T15:46:01,671][ERROR][logstash.pipeline        ] Pipeline aborted due to error {:pipeline_id=>"main", :exception=>#<LogStash::ConfigurationError: Must set :tracking_column if :use_column_value is true.>, :backtrace=>["C:/ELK/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:212:in `register'", "C:/ELK/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:341:in `register_plugin'", "C:/ELK/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:352:in `block in register_plugins'", "org/jruby/RubyArray.java:1734:in `each'", "C:/ELK/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:352:in `register_plugins'", "C:/ELK/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:502:in `start_inputs'", "C:/ELK/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:393:in `start_workers'", "C:/ELK/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:289:in `run'", "C:/ELK/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:249:in `block in start'"], :thread=>"#<Thread:0x3ecb9046 run>"}
[2018-05-08T15:46:01,706][ERROR][logstash.agent           ] Failed to execute action {:id=>:main, :action_type=>LogStash::ConvergeResult::FailedAction, :message=>"Could not execute action: LogStash::PipelineAction::Create/pipeline_id:main, action_result: false", :backtrace=>nil}
[2018-05-08T15:47:19,560][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T15:47:19,575][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T15:47:19,766][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T15:47:20,301][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T15:47:20,758][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T15:47:23,731][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_d66639a6-fdbf-4f98-8966-5aa5a376c5f7", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T15:47:23,922][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T15:47:24,285][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T15:47:24,296][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T15:47:24,486][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T15:47:24,533][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T15:47:24,537][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T15:47:24,552][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T15:47:24,568][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T15:47:24,608][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T15:47:25,038][ERROR][logstash.pipeline        ] Error registering plugin {:pipeline_id=>"main", :plugin=>"<LogStash::Inputs::Jdbc jdbc_driver_library=>\"c:/elk/logstash-6.2.3/lib/sqlserverdriver/mssql-jdbc-6.2.2.jre8.jar\", jdbc_driver_class=>\"com.microsoft.sqlserver.jdbc.SQLServerDriver\", jdbc_connection_string=>\"jdbc:sqlserver://10.6.201.6:1433;databaseName=CobraDGServer;\", jdbc_user=>\"logsync2\", jdbc_password=><password>, schedule=>\"* * * * *\", jdbc_default_timezone=>\"Asia/Shanghai\", statement=>\"SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= :sql_last_value;\", last_run_metadata_path=>\"result/test.logstash_jdbc_last_run\", use_column_value=>true, tracking_column_type=>\"timestamp\", id=>\"5faa16b4ce772cc0c3120f8bd6912e6c2ad9ebb5bc93d359f013e12e0d1541a6\", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>\"plain_668841cf-c310-416e-b0cb-5849883890ef\", enable_metric=>true, charset=>\"UTF-8\">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>\"info\", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, clean_run=>false, record_last_run=>true, lowercase_column_names=>true>", :error=>"Must set :tracking_column if :use_column_value is true.", :thread=>"#<Thread:0x6398a888 run>"}
[2018-05-08T15:47:25,578][ERROR][logstash.pipeline        ] Pipeline aborted due to error {:pipeline_id=>"main", :exception=>#<LogStash::ConfigurationError: Must set :tracking_column if :use_column_value is true.>, :backtrace=>["C:/ELK/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:212:in `register'", "C:/ELK/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:341:in `register_plugin'", "C:/ELK/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:352:in `block in register_plugins'", "org/jruby/RubyArray.java:1734:in `each'", "C:/ELK/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:352:in `register_plugins'", "C:/ELK/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:502:in `start_inputs'", "C:/ELK/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:393:in `start_workers'", "C:/ELK/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:289:in `run'", "C:/ELK/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:249:in `block in start'"], :thread=>"#<Thread:0x6398a888 run>"}
[2018-05-08T15:47:25,605][ERROR][logstash.agent           ] Failed to execute action {:id=>:main, :action_type=>LogStash::ConvergeResult::FailedAction, :message=>"Could not execute action: LogStash::PipelineAction::Create/pipeline_id:main, action_result: false", :backtrace=>nil}
[2018-05-08T15:48:39,683][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T15:48:39,699][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T15:48:39,889][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T15:48:40,364][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T15:48:40,810][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T15:48:43,789][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201804", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_fcbc598f-4921-4b3e-879e-20f1d4349ac1", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T15:48:44,006][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T15:48:44,370][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T15:48:44,409][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T15:48:44,570][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T15:48:44,624][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T15:48:44,628][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T15:48:44,645][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T15:48:44,662][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T15:48:44,701][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T15:48:45,235][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x4c6277c6 run>"}
[2018-05-08T15:48:45,398][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T15:49:01,523][INFO ][logstash.inputs.jdbc     ] (0.043000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:49:02,384][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T15:50:00,221][INFO ][logstash.inputs.jdbc     ] (0.003000s) SELECT TOP(10) * FROM dbo.FileLog2201804 where dbo.FileLog2201804.operationTime >= '1970-01-01T08:00:00.000';
[2018-05-08T15:50:47,235][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T15:50:47,801][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x4c6277c6 run>"}
[2018-05-08T15:59:48,431][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T15:59:48,447][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T15:59:48,625][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T15:59:49,056][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T15:59:49,496][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T15:59:52,596][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201805", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_da187eae-ca4b-407b-8040-1db041c63576", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T15:59:52,767][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T15:59:53,161][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T15:59:53,170][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T15:59:53,348][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T15:59:53,394][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T15:59:53,397][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T15:59:53,409][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T15:59:53,426][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T15:59:53,464][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T15:59:53,936][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x755a210 run>"}
[2018-05-08T15:59:54,051][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T16:00:03,029][INFO ][logstash.inputs.jdbc     ] (1.749000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= '1970-01-01T08:00:00.000';
[2018-05-08T16:00:03,753][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T16:01:00,119][INFO ][logstash.inputs.jdbc     ] (0.007000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= '2018-05-02T12:40:34.000';
[2018-05-08T16:02:00,309][INFO ][logstash.inputs.jdbc     ] (0.012000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= '2018-05-03T14:36:49.000';
[2018-05-08T16:03:00,206][INFO ][logstash.inputs.jdbc     ] (0.012000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= '2018-05-07T11:09:14.000';
[2018-05-08T16:04:00,100][INFO ][logstash.inputs.jdbc     ] (0.016000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= '2018-05-08T14:59:57.000';
[2018-05-08T16:05:00,320][INFO ][logstash.inputs.jdbc     ] (0.023000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= '2018-05-08T15:35:04.000';
[2018-05-08T16:06:00,216][INFO ][logstash.inputs.jdbc     ] (0.025000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= '2018-05-08T15:35:09.000';
[2018-05-08T16:07:00,102][INFO ][logstash.inputs.jdbc     ] (0.026000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= '2018-05-08T15:37:51.000';
[2018-05-08T16:07:51,829][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T16:07:52,874][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x755a210 run>"}
[2018-05-08T17:27:36,037][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T17:27:36,054][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T17:27:36,232][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T17:27:36,696][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T17:27:37,097][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T17:27:39,811][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201805", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_897054dd-262c-411a-a9d4-e4b5fcfd3fa0", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T17:27:39,981][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T17:27:40,317][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T17:27:40,325][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T17:27:40,511][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T17:27:40,560][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T17:27:40,563][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T17:27:40,577][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T17:27:40,594][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T17:27:40,631][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T17:27:41,071][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x74a83708 run>"}
[2018-05-08T17:27:41,149][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T17:28:01,469][INFO ][logstash.inputs.jdbc     ] (0.076000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= '1970-01-01T08:00:00.000'+1/12/24;
[2018-05-08T17:28:01,530][WARN ][logstash.inputs.jdbc     ] Exception when executing JDBC query {:exception=>#<Sequel::DatabaseError: Java::ComMicrosoftSqlserverJdbc::SQLServerException: å¨å° varchar å¼ '1970-01-01T08:00:00.000' è½¬æ¢ææ°æ®ç±»å int æ¶å¤±è´¥ã>}
[2018-05-08T17:28:16,908][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T17:28:17,637][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x74a83708 run>"}
[2018-05-08T17:30:53,013][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T17:30:53,029][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T17:30:53,208][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T17:30:53,679][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T17:30:54,079][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T17:30:56,741][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201805", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_d5c097aa-1771-4b52-b781-d9c34a231501", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T17:30:56,913][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T17:30:57,265][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T17:30:57,274][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T17:30:57,462][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T17:30:57,512][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T17:30:57,515][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T17:30:57,528][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T17:30:57,547][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T17:30:57,585][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T17:30:58,038][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x570d1f4d run>"}
[2018-05-08T17:30:58,127][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T17:31:01,438][ERROR][logstash.inputs.jdbc     ] Java::ComMicrosoftSqlserverJdbc::SQLServerException: 'cast' 附近有语法错误，需要 'AS'。: SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= cast((cast('1970-01-01T08:00:00.000') as int)-1.0/12/24) as datetime;
[2018-05-08T17:31:01,479][WARN ][logstash.inputs.jdbc     ] Exception when executing JDBC query {:exception=>#<Sequel::DatabaseError: Java::ComMicrosoftSqlserverJdbc::SQLServerException: 'cast' éè¿æè¯­æ³éè¯¯ï¼éè¦ 'AS'ã>}
[2018-05-08T17:32:00,258][ERROR][logstash.inputs.jdbc     ] Java::ComMicrosoftSqlserverJdbc::SQLServerException: 'cast' 附近有语法错误，需要 'AS'。: SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= cast((cast('1970-01-01T08:00:00.000') as int)-1.0/12/24) as datetime;
[2018-05-08T17:32:00,260][WARN ][logstash.inputs.jdbc     ] Exception when executing JDBC query {:exception=>#<Sequel::DatabaseError: Java::ComMicrosoftSqlserverJdbc::SQLServerException: 'cast' éè¿æè¯­æ³éè¯¯ï¼éè¦ 'AS'ã>}
[2018-05-08T17:32:06,758][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T17:32:07,612][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x570d1f4d run>"}
[2018-05-08T17:35:24,070][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"C:/ELK/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-05-08T17:35:24,084][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"C:/ELK/logstash-6.2.3/modules/netflow/configuration"}
[2018-05-08T17:35:24,264][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-08T17:35:24,714][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-08T17:35:25,135][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-08T17:35:27,550][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch id=>"localdlp", index=>"dlp201805", document_type=>"dlp", hosts=>[//localhost:9200], enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_63522566-d771-4117-bc2f-819aeccb7732", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-08T17:35:27,749][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-08T17:35:28,104][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-05-08T17:35:28,113][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-05-08T17:35:28,262][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-05-08T17:35:28,355][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-08T17:35:28,359][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-08T17:35:28,373][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-08T17:35:28,389][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-08T17:35:28,426][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-05-08T17:35:28,857][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x36e9d988 run>"}
[2018-05-08T17:35:28,935][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-08T17:36:01,474][INFO ][logstash.inputs.jdbc     ] (0.039000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'1970-01-01T08:00:00.000');
[2018-05-08T17:36:02,167][INFO ][logstash.outputs.file    ] Opening file {:path=>"D:/vrv.txt"}
[2018-05-08T17:37:00,289][INFO ][logstash.inputs.jdbc     ] (0.006000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-02T12:40:34.000');
[2018-05-08T17:38:00,176][INFO ][logstash.inputs.jdbc     ] (0.011000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-03T14:36:49.000');
[2018-05-08T17:39:00,073][INFO ][logstash.inputs.jdbc     ] (0.012000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-07T11:09:14.000');
[2018-05-08T17:40:00,286][INFO ][logstash.inputs.jdbc     ] (0.028000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T16:21:06.000');
[2018-05-08T17:41:00,199][INFO ][logstash.inputs.jdbc     ] (0.026000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:06:19.000');
[2018-05-08T17:42:00,115][INFO ][logstash.inputs.jdbc     ] (0.042000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:34:33.000');
[2018-05-08T17:43:00,285][INFO ][logstash.inputs.jdbc     ] (0.036000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:34:33.000');
[2018-05-08T17:44:00,177][INFO ][logstash.inputs.jdbc     ] (0.029000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:36:11.000');
[2018-05-08T17:45:00,064][INFO ][logstash.inputs.jdbc     ] (0.026000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:38:27.000');
[2018-05-08T17:46:00,261][INFO ][logstash.inputs.jdbc     ] (0.034000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:38:27.000');
[2018-05-08T17:47:00,154][INFO ][logstash.inputs.jdbc     ] (0.025000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:38:27.000');
[2018-05-08T17:48:00,073][INFO ][logstash.inputs.jdbc     ] (0.050000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:36:41.000');
[2018-05-08T17:49:00,242][INFO ][logstash.inputs.jdbc     ] (0.026000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:38:18.000');
[2018-05-08T17:50:00,128][INFO ][logstash.inputs.jdbc     ] (0.014000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:38:18.000');
[2018-05-08T17:51:00,337][INFO ][logstash.inputs.jdbc     ] (0.022000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:36:01.000');
[2018-05-08T17:52:00,229][INFO ][logstash.inputs.jdbc     ] (0.023000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:36:38.000');
[2018-05-08T17:53:00,120][INFO ][logstash.inputs.jdbc     ] (0.016000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:36:01.000');
[2018-05-08T17:54:00,054][INFO ][logstash.inputs.jdbc     ] (0.014000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:36:38.000');
[2018-05-08T17:55:00,273][INFO ][logstash.inputs.jdbc     ] (0.020000s) SELECT TOP(10) * FROM dbo.FileLog2201805 where dbo.FileLog2201805.operaTime >= dateadd(minute,-5,'2018-05-08T17:36:01.000');
[2018-05-08T17:55:37,220][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-08T17:55:38,492][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x36e9d988 run>"}
